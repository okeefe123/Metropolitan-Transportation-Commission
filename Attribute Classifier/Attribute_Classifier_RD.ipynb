{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "disturbed-warrior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/okeefe/Box/USF Data Science Practicum/2020-21/Okeefe/Project_1_Policy_Parsing\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "direct-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "from finished_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-hindu",
   "metadata": {},
   "source": [
    "# Multi-Class Classifier\n",
    "\n",
    "- Given the dataset constructed in \"Policy_Scraping\", create a machine learning algorithm which can predict if a line in a policy document holds relevant information for following attributes:\n",
    "    - max floor area ratio\n",
    "    - max dwellings per unit area\n",
    "    - building height\n",
    "    - minimum lot area (square feet)\n",
    "    - units per lot\n",
    "    \n",
    " \n",
    "## Data:\n",
    "\n",
    "- Will be using the records from the policy_scraper phase to train and test the model\n",
    "- Two model circumstances:\n",
    "    1. All the data scraped\n",
    "    2. Only scraped data with non-nan zone candidates\n",
    "    \n",
    "- Features: Vectorized centroid of \"Context\" (using spacy)\n",
    "- Label: \"Attribute\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "desperate-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('City_Zoning_Attributes_with_Zones.csv', index_col=\"Unnamed: 0\")\n",
    "#data = data[~data['Zone_Candidates'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "psychological-waterproof",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Values</th>\n",
       "      <th>Context</th>\n",
       "      <th>Policy Subsection</th>\n",
       "      <th>Line</th>\n",
       "      <th>Fraction</th>\n",
       "      <th>Zone_Candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oakland</td>\n",
       "      <td>max_dua</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Liquids: Capacity of an individual vessel exce...</td>\n",
       "      <td>Title 15 - BUILDINGS AND CONSTRUCTION</td>\n",
       "      <td>6287</td>\n",
       "      <td>56.467840</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oakland</td>\n",
       "      <td>max_dua</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A vehicle with one or more chassis-mounted tan...</td>\n",
       "      <td>Title 15 - BUILDINGS AND CONSTRUCTION</td>\n",
       "      <td>6347</td>\n",
       "      <td>57.006827</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oakland</td>\n",
       "      <td>max_dua</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Service of Notice and Order. The notice and or...</td>\n",
       "      <td>Title 15 - BUILDINGS AND CONSTRUCTION</td>\n",
       "      <td>7449</td>\n",
       "      <td>66.906216</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oakland</td>\n",
       "      <td>max_dua</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The penalties imposed pursuant to this Chapter...</td>\n",
       "      <td>Title 15 - BUILDINGS AND CONSTRUCTION</td>\n",
       "      <td>7528</td>\n",
       "      <td>67.615882</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oakland</td>\n",
       "      <td>max_dua</td>\n",
       "      <td>30.0</td>\n",
       "      <td>The penalties imposed on the building owner sh...</td>\n",
       "      <td>Title 15 - BUILDINGS AND CONSTRUCTION</td>\n",
       "      <td>8301</td>\n",
       "      <td>74.559828</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19035</th>\n",
       "      <td>mountain_view</td>\n",
       "      <td>minimum_lot_sqft</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>All new commercial buildings or groups of new ...</td>\n",
       "      <td>CHAPTER 8 - BUILDINGS</td>\n",
       "      <td>1915</td>\n",
       "      <td>57.982430</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19036</th>\n",
       "      <td>mountain_view</td>\n",
       "      <td>minimum_lot_sqft</td>\n",
       "      <td>1985.0, 900.0</td>\n",
       "      <td>Exception: This chapter shall not apply to Gro...</td>\n",
       "      <td>CHAPTER 8 - BUILDINGS</td>\n",
       "      <td>2014</td>\n",
       "      <td>60.981521</td>\n",
       "      <td>A105, A102, A109, A1-2, A107, A1-F, A106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19037</th>\n",
       "      <td>mountain_view</td>\n",
       "      <td>minimum_lot_sqft</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>\"2. Number and location of tests. The minimum ...</td>\n",
       "      <td>CHAPTER 8 - BUILDINGS</td>\n",
       "      <td>2051</td>\n",
       "      <td>62.102393</td>\n",
       "      <td>A1-H, A108, A107, A1-I, A1-F, A106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19038</th>\n",
       "      <td>mountain_view</td>\n",
       "      <td>minimum_lot_sqft</td>\n",
       "      <td>1985.0, 900.0, 1933.0</td>\n",
       "      <td>The provisions of this article shall apply to ...</td>\n",
       "      <td>CHAPTER 8 - BUILDINGS</td>\n",
       "      <td>2960</td>\n",
       "      <td>89.639503</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19039</th>\n",
       "      <td>mountain_view</td>\n",
       "      <td>minimum_lot_sqft</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>The minimum quantity of tests shall be as foll...</td>\n",
       "      <td>CHAPTER 8 - BUILDINGS</td>\n",
       "      <td>3080</td>\n",
       "      <td>93.274765</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19040 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                City         Attribute                 Values  \\\n",
       "0            oakland           max_dua                   55.0   \n",
       "1            oakland           max_dua                    1.0   \n",
       "2            oakland           max_dua                    3.0   \n",
       "3            oakland           max_dua                    5.0   \n",
       "4            oakland           max_dua                   30.0   \n",
       "...              ...               ...                    ...   \n",
       "19035  mountain_view  minimum_lot_sqft                25000.0   \n",
       "19036  mountain_view  minimum_lot_sqft          1985.0, 900.0   \n",
       "19037  mountain_view  minimum_lot_sqft                 1500.0   \n",
       "19038  mountain_view  minimum_lot_sqft  1985.0, 900.0, 1933.0   \n",
       "19039  mountain_view  minimum_lot_sqft                 1500.0   \n",
       "\n",
       "                                                 Context  \\\n",
       "0      Liquids: Capacity of an individual vessel exce...   \n",
       "1      A vehicle with one or more chassis-mounted tan...   \n",
       "2      Service of Notice and Order. The notice and or...   \n",
       "3      The penalties imposed pursuant to this Chapter...   \n",
       "4      The penalties imposed on the building owner sh...   \n",
       "...                                                  ...   \n",
       "19035  All new commercial buildings or groups of new ...   \n",
       "19036  Exception: This chapter shall not apply to Gro...   \n",
       "19037  \"2. Number and location of tests. The minimum ...   \n",
       "19038  The provisions of this article shall apply to ...   \n",
       "19039  The minimum quantity of tests shall be as foll...   \n",
       "\n",
       "                           Policy Subsection  Line   Fraction  \\\n",
       "0      Title 15 - BUILDINGS AND CONSTRUCTION  6287  56.467840   \n",
       "1      Title 15 - BUILDINGS AND CONSTRUCTION  6347  57.006827   \n",
       "2      Title 15 - BUILDINGS AND CONSTRUCTION  7449  66.906216   \n",
       "3      Title 15 - BUILDINGS AND CONSTRUCTION  7528  67.615882   \n",
       "4      Title 15 - BUILDINGS AND CONSTRUCTION  8301  74.559828   \n",
       "...                                      ...   ...        ...   \n",
       "19035                  CHAPTER 8 - BUILDINGS  1915  57.982430   \n",
       "19036                  CHAPTER 8 - BUILDINGS  2014  60.981521   \n",
       "19037                  CHAPTER 8 - BUILDINGS  2051  62.102393   \n",
       "19038                  CHAPTER 8 - BUILDINGS  2960  89.639503   \n",
       "19039                  CHAPTER 8 - BUILDINGS  3080  93.274765   \n",
       "\n",
       "                                Zone_Candidates  \n",
       "0                                           NaN  \n",
       "1                                           NaN  \n",
       "2                                           NaN  \n",
       "3                                           NaN  \n",
       "4                                           NaN  \n",
       "...                                         ...  \n",
       "19035                                       NaN  \n",
       "19036  A105, A102, A109, A1-2, A107, A1-F, A106  \n",
       "19037        A1-H, A108, A107, A1-I, A1-F, A106  \n",
       "19038                                       NaN  \n",
       "19039                                       NaN  \n",
       "\n",
       "[19040 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-baptist",
   "metadata": {},
   "source": [
    "## EDA to prepare Train/Validate/Test\n",
    "\n",
    "### Question: \n",
    "\n",
    "- Given the collected values from regular expressions, can we create a Multi-Class Classifier which more effectively and accurately identifies attributes?\n",
    "\n",
    "###  Classes:\n",
    "    1. max_dua\n",
    "    2. minimum_lot_sqft\n",
    "    3. units_per_lot\n",
    "    4. max_far\n",
    "    5. none\n",
    "   \n",
    "$$\\hspace{2mm}$$\n",
    "   \n",
    "### Metrics: \n",
    "    1. F1 score - Validation/Test\n",
    "    2. Collection counts for each attribute of a novel policy document (the jurisdiction will be omitted from the train/validate set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "changing-doubt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_dua             0.433718\n",
       "minimum_lot_sqft    0.314286\n",
       "building_height     0.178099\n",
       "units_per_lot       0.058403\n",
       "max_far             0.015494\n",
       "Name: Attribute, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Attribute'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-cannon",
   "metadata": {},
   "source": [
    "- Very unbalanced in terms of max_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "solved-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = data['City'].value_counts(normalize=True).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "narrative-physiology",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brentwood 0.08508403361344538\n",
      "sonoma_county 0.04543067226890756\n",
      "hayward 0.039285714285714285\n",
      "woodside 0.03335084033613445\n",
      "pacifica 0.02804621848739496\n",
      "alameda 0.025577731092436974\n",
      "milpitas 0.02542016806722689\n",
      "berkeley 0.024002100840336136\n",
      "santa_clara_county 0.021586134453781512\n",
      "burlingame 0.020640756302521008\n",
      "san_jose 0.02001050420168067\n",
      "marin_county 0.019852941176470587\n",
      "south san francisco 0.019012605042016805\n",
      "morgan_hill 0.018067226890756304\n",
      "vacaville 0.017489495798319328\n",
      "el_cerrito 0.017226890756302522\n",
      "san_rafael 0.016964285714285713\n",
      "sunnyvale 0.016911764705882352\n",
      "contra_costa_county 0.01638655462184874\n",
      "novato 0.015756302521008403\n",
      "santa rosa 0.015703781512605042\n",
      "mountain_view 0.015546218487394958\n",
      "los_gatos 0.015073529411764706\n",
      "richmond 0.014548319327731093\n",
      "los_altos 0.014180672268907563\n",
      "alameda_county 0.013865546218487394\n",
      "tiburon 0.012762605042016806\n",
      "union city 0.012657563025210084\n",
      "brisbane 0.0125\n",
      "sonoma 0.012394957983193277\n",
      "vallejo 0.012342436974789915\n",
      "napa 0.011764705882352941\n",
      "pleasant hill 0.01171218487394958\n",
      "san carlos 0.011449579831932772\n",
      "san_anselmo 0.011134453781512605\n",
      "saratoga 0.011029411764705883\n",
      "moraga 0.010661764705882353\n",
      "los altos hills 0.01050420168067227\n",
      "calistoga 0.010451680672268907\n"
     ]
    }
   ],
   "source": [
    "for key, val in data['City'].value_counts(normalize=True).items():\n",
    "    if val > median:\n",
    "        print(key, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-warehouse",
   "metadata": {},
   "source": [
    "# Test Set\n",
    "\n",
    "- Because Calistoga contains the median value counts, we will use it as our final test.\n",
    "    - Rationale: Not small enough to be inconsequential, yet also not large enough to be a significant count of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "assisted-supply",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['City'].value_counts()['calistoga']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-nickel",
   "metadata": {},
   "source": [
    "### Finding values for the Train/Validate/Test for lines where no attributes are found\n",
    "\n",
    "- For each city, parse through the documents and assign \"legitimate\" lines (greater than 4 words in length) the attribute \"none\"\n",
    "    - Rationale: \n",
    "        - We want the training set to reflect the real outcomes as accurately as possible! This means using all useful lines that can give insight into what distinguishes a \"none\" class from an attribute class\n",
    "    - Comments: \n",
    "        - This will lend to an extremely unbalanced data set (predominantly \"None\") and therefore we will eventually need to introduce some upsampling techniques\n",
    "        - We want to omit any \"empty\" or \"nonsensical\" lines which introduce no ambiguity (e.g. a line only containing empty quotes or brackets will not add anything to the classifier and thus should be omitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "indonesian-winning",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_dua             75\n",
       "minimum_lot_sqft    65\n",
       "none                49\n",
       "building_height     49\n",
       "units_per_lot        9\n",
       "max_far              1\n",
       "Name: Attribute, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "none_class_lines = []\n",
    "\n",
    "paths = get_policies(whitelist=whitelist, city='calistoga')\n",
    "\n",
    "for path in paths:\n",
    "        with open(path, 'r', encoding=\"utf-8\") as f:\n",
    "            file = f.read().split('\\n')\n",
    "        subsection = path.split(\"/\")[-1].split(\".\")[0]\n",
    "        policy_data = data[(data['City']=='calistoga') & (data['Policy Subsection']==subsection)]\n",
    "        attrib_idx = policy_data.Line.unique()\n",
    "        if len(attrib_idx) > 0:                                        # Don't bother with policy subsections where nothing was found!\n",
    "            for index in sorted(attrib_idx, reverse=True):             # Delete the lines containing found attributes\n",
    "                del file[index-1]                                      # Correction for the index 0 start\n",
    "            \n",
    "            # Drop all funky looking symbols so that there is a better representation of context\n",
    "            edited_contents = [line.replace('\\xa0', ' ') for line in file if len(line.split()) > 4]\n",
    "            none_class_lines.extend(edited_contents)\n",
    "            \n",
    "none_class_df = pd.DataFrame({'City': 'calistoga', 'Attribute': 'none', 'Context': none_class_lines})\n",
    "city_data = data[data['City']=='calistoga'][['City', 'Attribute', 'Context']]\n",
    "city_data_median = int(city_data['Attribute'].value_counts().median())\n",
    "total_none = len(none_class_df)\n",
    "sample_ratio = city_data_median / total_none\n",
    "none_class_df = none_class_df.sample(frac=sample_ratio)\n",
    "test_set = city_data.append(none_class_df)\n",
    "test_set['Attribute'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-canadian",
   "metadata": {},
   "source": [
    "# Train/Validate Set\n",
    "\n",
    "- Use the same procedure from above to find all \"non-attribute\" lines for every city in the train/validate set\n",
    "- To avoid the imbalance, the train/validation set will be split by class and then reappended so that the proportions remain similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "circular-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_none_attributes(city: str, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Appends all none attribute lines in policy subsections to prepare for classification model\"\"\"\n",
    "    none_class_lines = []\n",
    "\n",
    "    paths = get_policies(whitelist=whitelist, city=city, most_recent=True)\n",
    "\n",
    "    for path in paths:\n",
    "            with open(path, 'r', encoding=\"utf-8\") as f:\n",
    "                file = f.read().split('\\n')\n",
    "            subsection = path.split(\"/\")[-1].split(\".\")[0]\n",
    "            policy_data = df[(df['City']==city) & (df['Policy Subsection']==subsection)]\n",
    "            \n",
    "            attrib_idx = policy_data.Line.unique()\n",
    "            #print(policy_data)\n",
    "            if len(attrib_idx) > 0:                                        # Don't bother with policy subsections where nothing was found!\n",
    "                for index in sorted(attrib_idx, reverse=True):             # Delete the lines containing found attributes\n",
    "                    try:\n",
    "                        del file[index-1]                                  # Correction for the index 0 start\n",
    "                    except:                                                # Debug hints for stubborn policies\n",
    "                        print(path)\n",
    "                        print(file)\n",
    "                        print(index)\n",
    "                # Drop all funky looking symbols so that there is a better representation of context\n",
    "                edited_contents = [line.replace('\\xa0', ' ') for line in file if len(line.split()) > 4]\n",
    "                none_class_lines.extend(edited_contents)\n",
    "\n",
    "    none_class_df = pd.DataFrame({'City': city, 'Attribute': 'none', 'Context': none_class_lines})\n",
    "    city_data = df[df['City']==city][['City', 'Attribute', 'Context']]\n",
    "    \n",
    "    # Find \"none\" sampling size by setting it equal to the sum of the known classes\n",
    "    # total_known = len(city_data)\n",
    "    city_median = city_data['Attribute'].value_counts().median()\n",
    "    total_none = len(none_class_df)\n",
    "    \n",
    "    sample_ratio = city_median / total_none\n",
    "    print(sample_ratio)\n",
    "    print(city_data['Attribute'].value_counts())\n",
    "    none_class_df = none_class_df.sample(frac=sample_ratio)\n",
    "    \n",
    "    appended_df = city_data.append(none_class_df).set_index('City')\n",
    "    return appended_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dominant-handbook",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oakland: 0/77\n",
      "0.0022016398420892803\n",
      "max_dua             47\n",
      "minimum_lot_sqft    24\n",
      "building_height      5\n",
      "units_per_lot        2\n",
      "Name: Attribute, dtype: int64\n",
      "alameda: 1/77\n",
      "0.010465262892447359\n",
      "max_dua             169\n",
      "minimum_lot_sqft    157\n",
      "building_height      83\n",
      "units_per_lot        76\n",
      "max_far               2\n",
      "Name: Attribute, dtype: int64\n",
      "orinda: 2/77\n",
      "0.004024621212121212\n",
      "max_dua             51\n",
      "minimum_lot_sqft    42\n",
      "building_height     17\n",
      "units_per_lot        5\n",
      "max_far              2\n",
      "Name: Attribute, dtype: int64\n",
      "hillsborough: 3/77\n",
      "0.0037067545304777594\n",
      "minimum_lot_sqft    26\n",
      "max_dua             13\n",
      "max_far              9\n",
      "building_height      7\n",
      "units_per_lot        6\n",
      "Name: Attribute, dtype: int64\n",
      "dublin: 4/77\n",
      "0.005964214711729622\n",
      "max_dua             70\n",
      "minimum_lot_sqft    64\n",
      "building_height     24\n",
      "units_per_lot        8\n",
      "max_far              2\n",
      "Name: Attribute, dtype: int64\n",
      "menlo park: 5/77\n",
      "0.010842368640533779\n",
      "minimum_lot_sqft    16\n",
      "max_dua             13\n",
      "building_height      6\n",
      "Name: Attribute, dtype: int64\n",
      "rio vista: 6/77\n",
      "0.009776536312849162\n",
      "max_dua             83\n",
      "building_height     58\n",
      "minimum_lot_sqft    42\n",
      "units_per_lot       10\n",
      "max_far              4\n",
      "Name: Attribute, dtype: int64\n",
      "novato: 7/77\n",
      "0.004934054464370434\n",
      "max_dua             161\n",
      "minimum_lot_sqft     64\n",
      "building_height      52\n",
      "units_per_lot        17\n",
      "max_far               6\n",
      "Name: Attribute, dtype: int64\n",
      "napa_county: 8/77\n",
      "0.0044014084507042256\n",
      "max_dua             112\n",
      "building_height      30\n",
      "minimum_lot_sqft     25\n",
      "units_per_lot         9\n",
      "max_far               2\n",
      "Name: Attribute, dtype: int64\n",
      "cloverdale: 9/77\n",
      "0.005845595646039105\n",
      "max_dua             75\n",
      "minimum_lot_sqft    50\n",
      "building_height     29\n",
      "units_per_lot       15\n",
      "max_far              5\n",
      "Name: Attribute, dtype: int64\n",
      "daly_city: 10/77\n",
      "0.0070951585976627716\n",
      "max_dua             54\n",
      "units_per_lot       20\n",
      "minimum_lot_sqft    17\n",
      "building_height     11\n",
      "max_far              1\n",
      "Name: Attribute, dtype: int64\n",
      "el_cerrito: 11/77\n",
      "0.0034949759720401923\n",
      "max_dua             186\n",
      "minimum_lot_sqft     97\n",
      "units_per_lot        24\n",
      "building_height      17\n",
      "max_far               4\n",
      "Name: Attribute, dtype: int64\n",
      "san pablo: 12/77\n",
      "0.0032641641408253674\n",
      "max_dua             79\n",
      "building_height     19\n",
      "minimum_lot_sqft    14\n",
      "units_per_lot        7\n",
      "max_far              6\n",
      "Name: Attribute, dtype: int64\n",
      "brentwood: 13/77\n",
      "0.005813648981302048\n",
      "building_height     840\n",
      "max_dua             629\n",
      "minimum_lot_sqft    111\n",
      "units_per_lot        38\n",
      "max_far               2\n",
      "Name: Attribute, dtype: int64\n",
      "napa: 14/77\n",
      "0.0038955979742890533\n",
      "max_dua             114\n",
      "minimum_lot_sqft     80\n",
      "building_height      20\n",
      "units_per_lot         9\n",
      "max_far               1\n",
      "Name: Attribute, dtype: int64\n",
      "campbell: 15/77\n",
      "0.005110421609782807\n",
      "max_dua             98\n",
      "minimum_lot_sqft    34\n",
      "units_per_lot       22\n",
      "building_height     16\n",
      "Name: Attribute, dtype: int64\n",
      "brisbane: 16/77\n",
      "0.007255353034861086\n",
      "minimum_lot_sqft    91\n",
      "max_dua             84\n",
      "building_height     41\n",
      "max_far             13\n",
      "units_per_lot        9\n",
      "Name: Attribute, dtype: int64\n",
      "newark: 17/77\n",
      "0.005700712589073635\n",
      "max_dua             96\n",
      "building_height     42\n",
      "minimum_lot_sqft    30\n",
      "units_per_lot       17\n",
      "Name: Attribute, dtype: int64\n",
      "benicia: 18/77\n",
      "0.00261172373766686\n",
      "minimum_lot_sqft    8\n",
      "max_dua             7\n",
      "building_height     2\n",
      "units_per_lot       2\n",
      "Name: Attribute, dtype: int64\n",
      "cotati: 19/77\n",
      "0.003431372549019608\n",
      "max_dua             112\n",
      "minimum_lot_sqft     52\n",
      "building_height      21\n",
      "units_per_lot         5\n",
      "max_far               1\n",
      "Name: Attribute, dtype: int64\n",
      "los altos hills: 20/77\n",
      "0.013730874852883483\n",
      "minimum_lot_sqft    86\n",
      "building_height     63\n",
      "max_dua             35\n",
      "units_per_lot       14\n",
      "max_far              2\n",
      "Name: Attribute, dtype: int64\n",
      "hayward: 21/77\n",
      "0.007325644706231748\n",
      "minimum_lot_sqft    290\n",
      "max_dua             265\n",
      "building_height     148\n",
      "units_per_lot        38\n",
      "max_far               7\n",
      "Name: Attribute, dtype: int64\n",
      "berkeley: 22/77\n",
      "0.006609117885082277\n",
      "minimum_lot_sqft    231\n",
      "max_dua             149\n",
      "building_height      49\n",
      "units_per_lot        19\n",
      "max_far               9\n",
      "Name: Attribute, dtype: int64\n",
      "belmont: 23/77\n",
      "0.0016326530612244899\n",
      "max_dua             5\n",
      "max_far             2\n",
      "minimum_lot_sqft    1\n",
      "Name: Attribute, dtype: int64\n",
      "san carlos: 24/77\n",
      "0.005415441745319511\n",
      "max_dua             110\n",
      "minimum_lot_sqft     54\n",
      "building_height      35\n",
      "units_per_lot        15\n",
      "max_far               4\n",
      "Name: Attribute, dtype: int64\n",
      "redwood_city: 25/77\n",
      "0.003629764065335753\n",
      "building_height     2\n",
      "minimum_lot_sqft    2\n",
      "Name: Attribute, dtype: int64\n",
      "suisun_city: 26/77\n",
      "0.0028254288597376388\n",
      "max_dua             71\n",
      "minimum_lot_sqft    40\n",
      "building_height     14\n",
      "units_per_lot        4\n",
      "max_far              2\n",
      "Name: Attribute, dtype: int64\n",
      "vallejo: 27/77\n",
      "0.006466688403434409\n",
      "max_dua             96\n",
      "building_height     85\n",
      "units_per_lot       34\n",
      "minimum_lot_sqft    20\n",
      "Name: Attribute, dtype: int64\n",
      "south san francisco: 28/77\n",
      "0.005763688760806916\n",
      "minimum_lot_sqft    163\n",
      "max_dua             132\n",
      "building_height      38\n",
      "units_per_lot        20\n",
      "max_far               9\n",
      "Name: Attribute, dtype: int64\n",
      "san_rafael: 29/77\n",
      "0.00700218818380744\n",
      "minimum_lot_sqft    122\n",
      "max_dua             108\n",
      "building_height      48\n",
      "units_per_lot        38\n",
      "max_far               7\n",
      "Name: Attribute, dtype: int64\n",
      "millbrae: 30/77\n",
      "0.008416963418582066\n",
      "minimum_lot_sqft    47\n",
      "max_dua             46\n",
      "building_height     26\n",
      "units_per_lot        7\n",
      "max_far              5\n",
      "Name: Attribute, dtype: int64\n",
      "alameda_county: 31/77\n",
      "0.007401812688821752\n",
      "minimum_lot_sqft    98\n",
      "max_dua             94\n",
      "building_height     49\n",
      "units_per_lot       21\n",
      "max_far              2\n",
      "Name: Attribute, dtype: int64\n",
      "marin_county: 32/77\n",
      "0.005456453305351522\n",
      "max_dua             159\n",
      "minimum_lot_sqft    115\n",
      "building_height      52\n",
      "units_per_lot        35\n",
      "max_far              17\n",
      "Name: Attribute, dtype: int64\n",
      "sonoma: 33/77\n",
      "0.006648725660914991\n",
      "max_dua             97\n",
      "minimum_lot_sqft    93\n",
      "building_height     42\n",
      "units_per_lot        3\n",
      "max_far              1\n",
      "Name: Attribute, dtype: int64\n",
      "sunnyvale: 34/77\n",
      "0.007792678506705328\n",
      "max_dua             166\n",
      "minimum_lot_sqft     79\n",
      "building_height      43\n",
      "units_per_lot        18\n",
      "max_far              16\n",
      "Name: Attribute, dtype: int64\n",
      "moraga: 35/77\n",
      "0.012345679012345678\n",
      "max_dua             102\n",
      "minimum_lot_sqft     48\n",
      "building_height      42\n",
      "units_per_lot         9\n",
      "max_far               2\n",
      "Name: Attribute, dtype: int64\n",
      "emeryville: 36/77\n",
      "0.004472271914132379\n",
      "max_dua             11\n",
      "minimum_lot_sqft     5\n",
      "building_height      1\n",
      "Name: Attribute, dtype: int64\n",
      "san_anselmo: 37/77\n",
      "0.005759682224428997\n",
      "max_dua             106\n",
      "minimum_lot_sqft     45\n",
      "building_height      29\n",
      "units_per_lot        25\n",
      "max_far               7\n",
      "Name: Attribute, dtype: int64\n",
      "santa rosa: 38/77\n",
      "0.006126512482769184\n",
      "max_dua             151\n",
      "minimum_lot_sqft     94\n",
      "building_height      40\n",
      "units_per_lot        13\n",
      "max_far               1\n",
      "Name: Attribute, dtype: int64\n",
      "union city: 39/77\n",
      "0.0064065230052417\n",
      "max_dua             111\n",
      "minimum_lot_sqft     80\n",
      "building_height      33\n",
      "units_per_lot        12\n",
      "max_far               5\n",
      "Name: Attribute, dtype: int64\n",
      "pleasant hill: 40/77\n",
      "0.0034542314335060447\n",
      "minimum_lot_sqft    110\n",
      "max_dua              82\n",
      "building_height      18\n",
      "units_per_lot        10\n",
      "max_far               3\n",
      "Name: Attribute, dtype: int64\n",
      "lafayette: 41/77\n",
      "0.003697555086024751\n",
      "max_dua             84\n",
      "minimum_lot_sqft    38\n",
      "building_height     11\n",
      "units_per_lot        5\n",
      "Name: Attribute, dtype: int64\n",
      "los_gatos: 42/77\n",
      "0.007134929443475504\n",
      "max_dua             146\n",
      "minimum_lot_sqft     72\n",
      "building_height      45\n",
      "units_per_lot        18\n",
      "max_far               6\n",
      "Name: Attribute, dtype: int64\n",
      "portola_valley: 43/77\n",
      "0.0007776049766718507\n",
      "max_dua             40\n",
      "building_height     12\n",
      "minimum_lot_sqft     3\n",
      "units_per_lot        2\n",
      "max_far              1\n",
      "Name: Attribute, dtype: int64\n",
      "monte_sereno: 44/77\n",
      "0.012396694214876033\n",
      "minimum_lot_sqft    90\n",
      "max_dua             60\n",
      "building_height      9\n",
      "units_per_lot        6\n",
      "Name: Attribute, dtype: int64\n",
      "windsor: 45/77\n",
      "0.007008410092110532\n",
      "max_dua             41\n",
      "minimum_lot_sqft    33\n",
      "units_per_lot        2\n",
      "max_far              1\n",
      "Name: Attribute, dtype: int64\n",
      "contra_costa_county: 46/77\n",
      "0.004186744608578877\n",
      "max_dua             166\n",
      "minimum_lot_sqft     71\n",
      "building_height      53\n",
      "units_per_lot        18\n",
      "max_far               4\n",
      "Name: Attribute, dtype: int64\n",
      "san leandro: 47/77\n",
      "0.012256267409470752\n",
      "minimum_lot_sqft    33\n",
      "max_dua             11\n",
      "Name: Attribute, dtype: int64\n",
      "san_ramon: 48/77\n",
      "0.002282670724747955\n",
      "max_dua             65\n",
      "minimum_lot_sqft    12\n",
      "units_per_lot        2\n",
      "Name: Attribute, dtype: int64\n",
      "pittsburg: 49/77\n",
      "0.012795275590551181\n",
      "minimum_lot_sqft    39\n",
      "max_dua             26\n",
      "building_height      1\n",
      "Name: Attribute, dtype: int64\n",
      "vacaville: 50/77\n",
      "0.006418613980543576\n",
      "max_dua             161\n",
      "minimum_lot_sqft     95\n",
      "building_height      64\n",
      "max_far              10\n",
      "units_per_lot         3\n",
      "Name: Attribute, dtype: int64\n",
      "foster city: 51/77\n",
      "0.003422459893048128\n",
      "max_dua             59\n",
      "minimum_lot_sqft    20\n",
      "building_height     16\n",
      "units_per_lot        8\n",
      "max_far              2\n",
      "Name: Attribute, dtype: int64\n",
      "clayton: 52/77\n",
      "0.010575016523463317\n",
      "max_dua             79\n",
      "minimum_lot_sqft    78\n",
      "building_height     18\n",
      "units_per_lot        6\n",
      "Name: Attribute, dtype: int64\n",
      "mill valley: 53/77\n",
      "0.009497427779976256\n",
      "max_dua             82\n",
      "minimum_lot_sqft    41\n",
      "building_height     24\n",
      "units_per_lot        8\n",
      "max_far              6\n",
      "Name: Attribute, dtype: int64\n",
      "santa_clara_county: 54/77\n",
      "0.007897630710786764\n",
      "minimum_lot_sqft    170\n",
      "max_dua             156\n",
      "building_height      79\n",
      "max_far               4\n",
      "units_per_lot         2\n",
      "Name: Attribute, dtype: int64\n",
      "morgan_hill: 55/77\n",
      "0.002049530315969257\n",
      "minimum_lot_sqft    167\n",
      "max_dua             128\n",
      "building_height      24\n",
      "units_per_lot        23\n",
      "max_far               2\n",
      "Name: Attribute, dtype: int64\n",
      "tiburon: 56/77\n",
      "0.002261761158021713\n",
      "max_dua             179\n",
      "minimum_lot_sqft     32\n",
      "building_height      15\n",
      "units_per_lot         9\n",
      "max_far               8\n",
      "Name: Attribute, dtype: int64\n",
      "los_altos: 57/77\n",
      "0.01409460105112279\n",
      "minimum_lot_sqft    103\n",
      "max_dua              87\n",
      "building_height      59\n",
      "units_per_lot        18\n",
      "max_far               3\n",
      "Name: Attribute, dtype: int64\n",
      "rohnert_park: 58/77\n",
      "0.0037907505686125853\n",
      "max_dua             72\n",
      "minimum_lot_sqft    29\n",
      "building_height     20\n",
      "units_per_lot        9\n",
      "max_far              9\n",
      "Name: Attribute, dtype: int64\n",
      "yountville: 59/77\n",
      "0.00350109409190372\n",
      "max_dua             115\n",
      "minimum_lot_sqft     24\n",
      "building_height      16\n",
      "units_per_lot        12\n",
      "max_far               8\n",
      "Name: Attribute, dtype: int64\n",
      "half moon bay: 60/77\n",
      "0.005092417955488495\n",
      "max_dua             93\n",
      "minimum_lot_sqft    40\n",
      "building_height     27\n",
      "units_per_lot        6\n",
      "max_far              1\n",
      "Name: Attribute, dtype: int64\n",
      "east_palo_alto: 61/77\n",
      "0.01055662188099808\n",
      "max_dua             55\n",
      "minimum_lot_sqft    44\n",
      "building_height      5\n",
      "Name: Attribute, dtype: int64\n",
      "atherton: 62/77\n",
      "0.010063819342169858\n",
      "building_height     34\n",
      "max_dua             33\n",
      "minimum_lot_sqft     8\n",
      "units_per_lot        6\n",
      "Name: Attribute, dtype: int64\n",
      "pacifica: 63/77\n",
      "0.014193717965567091\n",
      "max_dua             277\n",
      "minimum_lot_sqft    168\n",
      "building_height      48\n",
      "units_per_lot        41\n",
      "Name: Attribute, dtype: int64\n",
      "livermore: 64/77\n",
      "0.0017513134851138354\n",
      "max_dua             5\n",
      "building_height     2\n",
      "minimum_lot_sqft    1\n",
      "Name: Attribute, dtype: int64\n",
      "milpitas: 65/77\n",
      "0.004221155437841417\n",
      "max_dua             244\n",
      "minimum_lot_sqft    144\n",
      "building_height      51\n",
      "units_per_lot        29\n",
      "max_far              16\n",
      "Name: Attribute, dtype: int64\n",
      "saratoga: 66/77\n",
      "0.010454065469904962\n",
      "max_dua             98\n",
      "minimum_lot_sqft    60\n",
      "building_height     39\n",
      "units_per_lot       13\n",
      "Name: Attribute, dtype: int64\n",
      "burlingame: 67/77\n",
      "0.021607186210245204\n",
      "minimum_lot_sqft    158\n",
      "max_dua              96\n",
      "building_height      89\n",
      "max_far              32\n",
      "units_per_lot        18\n",
      "Name: Attribute, dtype: int64\n",
      "woodside: 68/77\n",
      "0.013462305544475469\n",
      "minimum_lot_sqft    487\n",
      "max_dua             104\n",
      "building_height      31\n",
      "units_per_lot        13\n",
      "Name: Attribute, dtype: int64\n",
      "american canyon: 69/77\n",
      "0.0035398230088495575\n",
      "max_dua             81\n",
      "minimum_lot_sqft    13\n",
      "building_height     11\n",
      "units_per_lot        9\n",
      "Name: Attribute, dtype: int64\n",
      "sonoma_county: 70/77\n",
      "0.01010192937750273\n",
      "max_dua             431\n",
      "minimum_lot_sqft    240\n",
      "units_per_lot       111\n",
      "building_height      81\n",
      "max_far               2\n",
      "Name: Attribute, dtype: int64\n",
      "richmond: 71/77\n",
      "0.011690509152438086\n",
      "max_dua             116\n",
      "minimum_lot_sqft    106\n",
      "building_height      46\n",
      "units_per_lot         9\n",
      "Name: Attribute, dtype: int64\n",
      "san_jose: 72/77\n",
      "0.0073937153419593345\n",
      "max_dua             145\n",
      "minimum_lot_sqft    137\n",
      "building_height      76\n",
      "units_per_lot        18\n",
      "max_far               5\n",
      "Name: Attribute, dtype: int64\n",
      "san bruno: 73/77\n",
      "0.0037669512807634357\n",
      "max_dua             69\n",
      "minimum_lot_sqft    15\n",
      "units_per_lot       15\n",
      "building_height     15\n",
      "max_far              5\n",
      "Name: Attribute, dtype: int64\n",
      "martinez: 74/77\n",
      "0.007407407407407408\n",
      "minimum_lot_sqft    97\n",
      "max_dua             41\n",
      "building_height     33\n",
      "units_per_lot        5\n",
      "max_far              1\n",
      "Name: Attribute, dtype: int64\n",
      "pleasanton: 75/77\n",
      "0.0055423594615993665\n",
      "max_dua             103\n",
      "minimum_lot_sqft     62\n",
      "building_height      21\n",
      "units_per_lot         9\n",
      "max_far               3\n",
      "Name: Attribute, dtype: int64\n",
      "mountain_view: 76/77\n",
      "0.010468072379243309\n",
      "minimum_lot_sqft    122\n",
      "max_dua              86\n",
      "building_height      70\n",
      "units_per_lot        14\n",
      "max_far               4\n",
      "Name: Attribute, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_valid = data[data['City'] != 'calistoga']\n",
    "cities = train_valid['City'].unique()\n",
    "\n",
    "new_df = pd.DataFrame(columns = ['City', 'Attribute', 'Context'])\n",
    "\n",
    "for i, city in enumerate(cities):\n",
    "    print(f\"{city}: {i}/{len(cities)}\")\n",
    "    city_df = add_none_attributes(city, data)\n",
    "    new_df = new_df.append(city_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "declared-klein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_dua             8183\n",
       "minimum_lot_sqft    5919\n",
       "building_height     3342\n",
       "none                2909\n",
       "units_per_lot       1103\n",
       "max_far              294\n",
       "Name: Attribute, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['Attribute'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "french-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling minority data points\n",
    "\n",
    "df_majority = new_df[~(new_df['Attribute'] == 'max_far') & ~(new_df['Attribute'] == 'units_per_lot')]\n",
    "df_majority_median = int(df_majority['Attribute'].value_counts().median())\n",
    "df_max_far = new_df[new_df['Attribute'] == 'max_far']\n",
    "df_units_per_lot = new_df[new_df['Attribute'] == 'units_per_lot']\n",
    "\n",
    "ratio_max_far = int(df_majority_median / len(df_max_far))\n",
    "ratio_units_per_lot = int(df_majority_median / len(df_units_per_lot))\n",
    "\n",
    "usamp_max_far = df_max_far.sample(len(df_max_far)*10, replace=True)\n",
    "usamp_units_per_lot = df_units_per_lot.sample(len(df_units_per_lot)*2, replace=True)\n",
    "\n",
    "usamp_df = pd.concat([df_majority, usamp_max_far], axis=0)\n",
    "usamp_df = pd.concat([usamp_df, usamp_units_per_lot], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "boring-column",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_dua             8183\n",
       "minimum_lot_sqft    5919\n",
       "building_height     3342\n",
       "max_far             2940\n",
       "none                2909\n",
       "units_per_lot       2206\n",
       "Name: Attribute, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usamp_df['Attribute'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-andorra",
   "metadata": {},
   "source": [
    "### Evenly splitting the new dataframe \n",
    "\n",
    "- Take each attribute of df and split it 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "political-float",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_dua             6546\n",
       "minimum_lot_sqft    4735\n",
       "building_height     2674\n",
       "max_far             2352\n",
       "none                2327\n",
       "units_per_lot       1765\n",
       "Name: Attribute, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Attribute'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "lightweight-rwanda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_dua             1637\n",
       "minimum_lot_sqft    1184\n",
       "building_height      668\n",
       "max_far              588\n",
       "none                 582\n",
       "units_per_lot        441\n",
       "Name: Attribute, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid['Attribute'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efficient-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train) + len(valid) == len(usamp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "abstract-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[[i for i in train.columns if i != 'Attribute']]\n",
    "X_valid = valid[[i for i in valid.columns if i != 'Attribute']]\n",
    "y_train = train['Attribute']\n",
    "y_valid = valid['Attribute']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-smart",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "- Tokenize context using spacy_tokenizer, calculate char/word count and average word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ongoing-bible",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.pipeline                import Pipeline, FeatureUnion\n",
    "from sklearn.svm                     import LinearSVC      # baseline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from   sklearn.ensemble              import RandomForestClassifier\n",
    "from sklearn.preprocessing           import *\n",
    "from sklearn.impute                  import SimpleImputer\n",
    "from sklearn.compose                 import ColumnTransformer\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def spacy_tokenizer(string: str) -> str:\n",
    "    doc = nlp(string)\n",
    "    new_string = \" \".join([token.lemma_ for token in doc if not token.is_stop])\n",
    "    return new_string\n",
    "\n",
    "def numerical_features(X_df: pd.DataFrame) -> None:\n",
    "    tokens = X_df['Context'].apply(lambda x: re.sub(r'[^\\w\\s]', '', spacy_tokenizer(x).strip()))\n",
    "    X_df['Char Count'] = tokens.apply(lambda x: len(x))\n",
    "    X_df['Word Count'] = tokens.apply(lambda x: len(x.split()))\n",
    "    X_df['Avg Word Length'] = X['Char Count'] / X['Word Count']\n",
    "    \n",
    "def encode_cities_mean_frequency(X_df: pd.DataFrame) -> None:\n",
    "    keys = X_df['City'].value_counts().index.values\n",
    "    vals = (X_df['City'].value_counts() / len(X_df)).values\n",
    "    encode_cities = dict(zip(keys, vals))\n",
    "\n",
    "    X_df['City'] = X_df['City'].map(lambda x: encode_cities[x])\n",
    "    \n",
    "def encode_label(y_df: pd.DataFrame) -> None:\n",
    "    encode_labels = {'max_dua'          : 0,\n",
    "                     'minimum_lot_sqft' : 1,\n",
    "                     'building_height'  : 2,\n",
    "                     'units_per_lot'    : 3,\n",
    "                     'max_far'          : 4, \n",
    "                     'none'             : 5\n",
    "    }\n",
    "\n",
    "    y_df = y_df.map(lambda y: encode_labels[y])\n",
    "    \n",
    "def preprocess_pipeline(X_df, y_df):\n",
    "    # Tokenize the Context column\n",
    "\n",
    "    # Update X_df with number variables\n",
    "    numerical_features(X_df)\n",
    "    \n",
    "    # Tokenize the Context column into a sparse matrix\n",
    "    vectorizer = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))\n",
    "    sparse = vectorizer.fit_transform(X_df['Context'])    \n",
    "    \n",
    "    #encode the \"cities\" feature\n",
    "    encode_cities_mean_frequency(X_df)\n",
    "    \n",
    "    # transform sparse CV matrix such that each dimension is given its own column\n",
    "    # drop context and join X_df with sparse (dataframe)\n",
    "    X_df = X_df.join(pd.DataFrame(sparse.todense())).drop(['Context'], axis=1)\n",
    "    \n",
    "    #encode the labels\n",
    "    encode_label(y_df)\n",
    "    \n",
    "    return X_df, y_df\n",
    "\n",
    "    \n",
    "    \n",
    "classifier = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "committed-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= pd.read_csv('ML-Modeling-Data/X_train.csv', index_col='Unnamed: 0')\n",
    "y_train= pd.read_csv('ML-Modeling-Data/y_train.csv', index_col='Unnamed: 0')\n",
    "X_valid= pd.read_csv('ML-Modeling-Data/X_valid.csv', index_col='Unnamed: 0')\n",
    "y_valid= pd.read_csv('ML-Modeling-Data/y_valid.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "forced-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = X_train.append(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "color-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = X_df.drop(['City', 'Char Count', 'Word Count', 'Avg Word Length'], axis=1).rename(columns={'index':'City'})\n",
    "X_df.to_csv('X_from_pipeline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "south-hampshire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5374</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7544</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25499 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Attribute\n",
       "656           0\n",
       "5374          0\n",
       "7544          0\n",
       "2570          0\n",
       "4772          0\n",
       "...         ...\n",
       "2189          3\n",
       "2191          3\n",
       "2200          3\n",
       "2202          3\n",
       "2203          3\n",
       "\n",
       "[25499 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "accurate-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = y_train.append(y_valid)\n",
    "\n",
    "decode = {0 : 'max_dua',\n",
    "          1 : 'minimum_lot_sqft',\n",
    "          2 : 'building_height',\n",
    "          3 : 'units_per_lot',\n",
    "          4 : 'max_far',\n",
    "          5 : 'none'  \n",
    "}\n",
    "\n",
    "y_df = y_df['Attribute'].map(lambda x: decode[x])\n",
    "\n",
    "y_df.to_csv('y_from_pipeline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "equivalent-peninsula",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5377efee29fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_for_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[^\\w\\s]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacy_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Char Count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Word Count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Avg Word Length'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Char Count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Word Count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def numerical_features(X: pd.DataFrame) -> None:\n",
    "    tokens = X['Context'].apply(lambda x: re.sub(r'[^\\w\\s]', '', spacy_tokenizer(x).strip()))\n",
    "    X['Char Count'] = tokens.apply(lambda x: len(x))\n",
    "    X['Word Count'] = tokens.apply(lambda x: len(x.split()))\n",
    "    X['Avg Word Length'] = X['Char Count'] / X['Word Count']\n",
    "    \n",
    "numerical_features(X_train)\n",
    "numerical_features(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "basic-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('ML-Modeling-Data/X_train.csv')\n",
    "X_valid.to_csv('ML-Modeling-Data/X_valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-brunei",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "informative-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('ML-Modeling-Data/X_train.csv')\n",
    "X_valid = pd.read_csv('ML-Modeling-Data/X_valid.csv')\n",
    "y_train = pd.read_csv('ML-Modeling-Data/y_train.csv')\n",
    "y_valid = pd.read_csv('ML-Modeling-Data/y_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "surrounded-gasoline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20399, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.drop(['City', 'Unnamed: 0'], axis=1, inplace=True)\n",
    "X_train.rename(columns={'index':'City'}, inplace=True)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "entitled-madison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5100, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.drop(['City', 'Unnamed: 0'], axis=1, inplace=True)\n",
    "X_valid.rename(columns={'index':'City'}, inplace=True)\n",
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "local-thong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>City</th>\n",
       "      <th>Char Count</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Avg Word Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F.    Occupancy of an individually partitioned...</td>\n",
       "      <td>dublin</td>\n",
       "      <td>132</td>\n",
       "      <td>18</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.     Any portion of the lot having a slope o...</td>\n",
       "      <td>napa</td>\n",
       "      <td>80</td>\n",
       "      <td>14</td>\n",
       "      <td>5.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B. Applicant is the bona fide owner of the pre...</td>\n",
       "      <td>pittsburg</td>\n",
       "      <td>279</td>\n",
       "      <td>37</td>\n",
       "      <td>7.540541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where permitted or conditionally permitted by ...</td>\n",
       "      <td>alameda</td>\n",
       "      <td>108</td>\n",
       "      <td>14</td>\n",
       "      <td>7.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The review authority may grant a detached two-...</td>\n",
       "      <td>tiburon</td>\n",
       "      <td>225</td>\n",
       "      <td>33</td>\n",
       "      <td>6.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20394</th>\n",
       "      <td>A.       Only one other residential unit shall...</td>\n",
       "      <td>pleasanton</td>\n",
       "      <td>456</td>\n",
       "      <td>62</td>\n",
       "      <td>7.354839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20395</th>\n",
       "      <td>R-6; One unit per 2,000 square feet of lot area.</td>\n",
       "      <td>alameda</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20396</th>\n",
       "      <td>Common Open Space. Developments which have eit...</td>\n",
       "      <td>morgan_hill</td>\n",
       "      <td>639</td>\n",
       "      <td>89</td>\n",
       "      <td>7.179775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20397</th>\n",
       "      <td>Live/Work Unit 1 space per unit for each unit ...</td>\n",
       "      <td>el_cerrito</td>\n",
       "      <td>124</td>\n",
       "      <td>24</td>\n",
       "      <td>5.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20398</th>\n",
       "      <td>\"Dwelling unit\" means a room, or a suite of co...</td>\n",
       "      <td>alameda_county</td>\n",
       "      <td>414</td>\n",
       "      <td>57</td>\n",
       "      <td>7.263158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20399 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Context            City  \\\n",
       "0      F.    Occupancy of an individually partitioned...          dublin   \n",
       "1      2.     Any portion of the lot having a slope o...            napa   \n",
       "2      B. Applicant is the bona fide owner of the pre...       pittsburg   \n",
       "3      Where permitted or conditionally permitted by ...         alameda   \n",
       "4      The review authority may grant a detached two-...         tiburon   \n",
       "...                                                  ...             ...   \n",
       "20394  A.       Only one other residential unit shall...      pleasanton   \n",
       "20395   R-6; One unit per 2,000 square feet of lot area.         alameda   \n",
       "20396  Common Open Space. Developments which have eit...     morgan_hill   \n",
       "20397  Live/Work Unit 1 space per unit for each unit ...      el_cerrito   \n",
       "20398  \"Dwelling unit\" means a room, or a suite of co...  alameda_county   \n",
       "\n",
       "       Char Count  Word Count  Avg Word Length  \n",
       "0             132          18         7.333333  \n",
       "1              80          14         5.714286  \n",
       "2             279          37         7.540541  \n",
       "3             108          14         7.714286  \n",
       "4             225          33         6.818182  \n",
       "...           ...         ...              ...  \n",
       "20394         456          62         7.354839  \n",
       "20395          35           7         5.000000  \n",
       "20396         639          89         7.179775  \n",
       "20397         124          24         5.166667  \n",
       "20398         414          57         7.263158  \n",
       "\n",
       "[20399 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "happy-kruger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>City</th>\n",
       "      <th>Char Count</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Avg Word Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F.    Occupancy of an individually partitioned...</td>\n",
       "      <td>dublin</td>\n",
       "      <td>132</td>\n",
       "      <td>18</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.     Any portion of the lot having a slope o...</td>\n",
       "      <td>napa</td>\n",
       "      <td>80</td>\n",
       "      <td>14</td>\n",
       "      <td>5.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B. Applicant is the bona fide owner of the pre...</td>\n",
       "      <td>pittsburg</td>\n",
       "      <td>279</td>\n",
       "      <td>37</td>\n",
       "      <td>7.540541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where permitted or conditionally permitted by ...</td>\n",
       "      <td>alameda</td>\n",
       "      <td>108</td>\n",
       "      <td>14</td>\n",
       "      <td>7.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The review authority may grant a detached two-...</td>\n",
       "      <td>tiburon</td>\n",
       "      <td>225</td>\n",
       "      <td>33</td>\n",
       "      <td>6.818182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context       City  Char Count  \\\n",
       "0  F.    Occupancy of an individually partitioned...     dublin         132   \n",
       "1  2.     Any portion of the lot having a slope o...       napa          80   \n",
       "2  B. Applicant is the bona fide owner of the pre...  pittsburg         279   \n",
       "3  Where permitted or conditionally permitted by ...    alameda         108   \n",
       "4  The review authority may grant a detached two-...    tiburon         225   \n",
       "\n",
       "   Word Count  Avg Word Length  \n",
       "0          18         7.333333  \n",
       "1          14         5.714286  \n",
       "2          37         7.540541  \n",
       "3          14         7.714286  \n",
       "4          33         6.818182  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = X_train.append(X_valid)\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-uganda",
   "metadata": {},
   "source": [
    "- Count-Vectorize the context column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "national-processing",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))\n",
    "#X_train['Token_Count']\n",
    "sparse = vectorizer.fit_transform(X_df['Context'])\n",
    "# sparse_valid = vectorizer.fit_transform(X_valid['Context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "failing-chain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20399, 5), (5100, 5))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-spare",
   "metadata": {},
   "source": [
    "- Encode the cities into their mean frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "equal-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = X_df['City'].value_counts().index.values\n",
    "vals = (X_df['City'].value_counts() / len(X_df)).values\n",
    "encode_cities = dict(zip(keys, vals))\n",
    "\n",
    "X_df['City'] = X_df['City'].map(lambda x: encode_cities[x])\n",
    "# X_valid['City'] = X_valid['City'].map(lambda x: encode_cities[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "yellow-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.join(pd.DataFrame(sparse_train.todense())).drop(['Context'], axis=1)\n",
    "# X_valid = X_valid.join(pd.DataFrame(sparse_valid.todense())).drop(['Context'], axis=1)\n",
    "X_df = X_df.join(pd.DataFrame(sparse.todense())).drop(['Context'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "extraordinary-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.drop(['Tokens'], axis=1, inplace = True)\n",
    "# X_valid.drop(['Tokens'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-mapping",
   "metadata": {},
   "source": [
    "- Encode the labels as numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "conventional-happening",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-653b3b32803a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencode_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencode_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   3907\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3908\u001b[0m         \"\"\"\n\u001b[0;32m-> 3909\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3910\u001b[0m         return self._constructor(new_values, index=self.index).__finalize__(\n\u001b[1;32m   3911\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"map\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-653b3b32803a>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencode_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencode_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "encode_labels = {'max_dua'          : 0,\n",
    "                 'minimum_lot_sqft' : 1,\n",
    "                 'building_height'  : 2,\n",
    "                 'units_per_lot'    : 3,\n",
    "                 'max_far'          : 4, \n",
    "                 'none'             : 5\n",
    "}\n",
    "\n",
    "y_train = y_train.map(lambda x: encode_labels[x])\n",
    "y_valid = y_valid.map(lambda x: encode_labels[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "valued-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = y_train.append(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "advanced-literacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Char Count</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Avg Word Length</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008745</td>\n",
       "      <td>132</td>\n",
       "      <td>18</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003726</td>\n",
       "      <td>126</td>\n",
       "      <td>19</td>\n",
       "      <td>6.631579</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010432</td>\n",
       "      <td>80</td>\n",
       "      <td>14</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003726</td>\n",
       "      <td>1309</td>\n",
       "      <td>175</td>\n",
       "      <td>7.480000</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003608</td>\n",
       "      <td>279</td>\n",
       "      <td>37</td>\n",
       "      <td>7.540541</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       City  Char Count  Word Count  Avg Word Length  0   1  2  3  4  5  ...  \\\n",
       "0  0.008745         132          18         7.333333  0  20  0  0  0  0  ...   \n",
       "0  0.003726         126          19         6.631579  0  20  0  0  0  0  ...   \n",
       "1  0.010432          80          14         5.714286  0  22  0  0  0  0  ...   \n",
       "1  0.003726        1309         175         7.480000  0  22  0  0  0  0  ...   \n",
       "2  0.003608         279          37         7.540541  0  53  0  0  0  0  ...   \n",
       "\n",
       "   88  89  90  91  92  93  94  95  96  97  \n",
       "0   0   0   0   0   0   0   0   0   0   0  \n",
       "0   0   0   0   0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "constant-parker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290     0\n",
       "1828    0\n",
       "4984    0\n",
       "189     0\n",
       "5731    0\n",
       "Name: Attribute, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "exclusive-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.to_csv('ML-Modeling-Data/X.csv')\n",
    "y_df.to_csv('ML-Modeling-Data/y.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-polish",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bacterial-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.read_csv('ML-Modeling-Data/X.csv')\n",
    "y_df = pd.read_csv('ML-Modeling-Data/y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "necessary-joseph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 5, 4, 3])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "revised-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = y_df['Attribute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "proprietary-bargain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 5, 4, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "studied-candidate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "25494    3\n",
       "25495    3\n",
       "25496    3\n",
       "25497    3\n",
       "25498    3\n",
       "Name: Attribute, Length: 25499, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "entitled-vinyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(columns=X_df.columns)\n",
    "X_valid = pd.DataFrame(columns=X_df.columns)\n",
    "y_train = pd.Series(name = y_df.name, dtype=int)\n",
    "y_valid = pd.Series(name = y_df.name, dtype=int)\n",
    "\n",
    "for attr in y_df.unique():\n",
    "    subset_X = X_df[y_df == attr].reset_index()\n",
    "    Xtrain_split = subset_X.sample(frac=0.8)\n",
    "    Xvalid_split = subset_X.loc[~subset_X.index.isin(Xtrain_split.index)]\n",
    "    X_train = X_train.append(Xtrain_split)\n",
    "    X_valid = X_valid.append(Xvalid_split)\n",
    "    \n",
    "    subset_y = y_df[y_df == attr].reset_index()\n",
    "    ytrain_split = subset_y.sample(frac=0.8)['Attribute']\n",
    "    yvalid_split = subset_y.loc[~subset_y.index.isin(ytrain_split.index)]['Attribute']\n",
    "    y_train = y_train.append(ytrain_split)\n",
    "    y_valid = y_valid.append(yvalid_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "wound-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X_train) + len(X_valid) == len(X_df)\n",
    "assert len(y_train) + len(y_valid) == len(y_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-drill",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Convert to numpy array for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "logical-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('ML-Modeling-Data/X_train_pp.csv')\n",
    "y_train.to_csv('ML-Modeling-Data/y_train_pp.csv')\n",
    "X_valid.to_csv('ML-Modeling-Data/X_valid_pp.csv')\n",
    "y_valid.to_csv('ML-Modeling-Data/y_valid_pp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "professional-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train['Unnamed: 0']\n",
    "del X_train['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "scientific-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_valid['Unnamed: 0']\n",
    "del X_valid['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-guarantee",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "offensive-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= pd.read_csv('ML-Modeling-Data/X_train_pp.csv', index_col='Unnamed: 0')\n",
    "y_train= pd.read_csv('ML-Modeling-Data/y_train_pp.csv', index_col='Unnamed: 0')\n",
    "X_valid= pd.read_csv('ML-Modeling-Data/X_valid_pp.csv', index_col='Unnamed: 0')\n",
    "y_valid= pd.read_csv('ML-Modeling-Data/y_valid_pp.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "about-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "divided-waterproof",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-78-ef16a25739a4>:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  tree.fit(X_train, y_train)\n"
     ]
    }
   ],
   "source": [
    "tree = RandomForestClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "colored-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Models/attrib_classifier_rf.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ahead-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "agricultural-identification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.56      0.64      2140\n",
      "           1       0.55      0.57      0.56      1159\n",
      "           2       0.27      0.46      0.34       395\n",
      "           3       0.19      0.38      0.25       216\n",
      "           4       0.49      0.42      0.45       678\n",
      "           5       0.27      0.31      0.29       512\n",
      "\n",
      "    accuracy                           0.50      5100\n",
      "   macro avg       0.42      0.45      0.42      5100\n",
      "weighted avg       0.56      0.50      0.52      5100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_pred, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "everyday-agreement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/okeefe/.pyenv/versions/3.8.1/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         max_dua       0.81      0.49      0.61      2732\n",
      "minimum_lot_sqft       0.51      0.56      0.53      1062\n",
      " building_height       0.05      0.49      0.09        71\n",
      "   units_per_lot       0.17      0.50      0.25       151\n",
      "         max_far       0.48      0.40      0.44       714\n",
      "            none       0.22      0.34      0.27       370\n",
      "\n",
      "        accuracy                           0.48      5100\n",
      "       macro avg       0.37      0.46      0.37      5100\n",
      "    weighted avg       0.63      0.48      0.53      5100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GBC = GradientBoostingClassifier()\n",
    "GBC.fit(X_train, y_train)\n",
    "y_pred = GBC.predict(X_valid)\n",
    "\n",
    "encode_labels = {'max_dua'          : 0,\n",
    "                 'minimum_lot_sqft' : 1,\n",
    "                 'building_height'  : 2,\n",
    "                 'units_per_lot'    : 3,\n",
    "                 'max_far'          : 4, \n",
    "                 'none'             : 5\n",
    "}\n",
    "\n",
    "\n",
    "print(classification_report(y_pred, y_valid, target_names=encode_labels.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "medieval-france",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/okeefe/.pyenv/versions/3.8.1/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 4,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 500,\n",
       " 'n_iter_no_change': None,\n",
       " 'random_state': None,\n",
       " 'subsample': 0.5,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "search_space = {'learning_rate'    : [0.1, 0.001, 0.0001, 0.00001],\n",
    "                'max_depth'        : [2, 3, 4, 5],\n",
    "                'min_samples_leaf' : [1, 2, 4, 6],\n",
    "                'n_estimators'     : [10, 20, 50, 100, 150, 200, 500],\n",
    "                'subsample'        : [0.2, 0.4, 0.5, 0.6, 0.8, 0.9]\n",
    "                }\n",
    "\n",
    "clf_random = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                                param_distributions=search_space,\n",
    "                                n_iter=50,\n",
    "                                cv=5,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=1)\n",
    "\n",
    "best_model = clf_random.fit(X_train, y_train)\n",
    "best_model.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "detailed-dakota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         max_dua       0.75      0.54      0.62      2270\n",
      "minimum_lot_sqft       0.55      0.56      0.55      1165\n",
      " building_height       0.17      0.44      0.25       257\n",
      "   units_per_lot       0.25      0.43      0.31       254\n",
      "         max_far       0.47      0.43      0.45       646\n",
      "            none       0.29      0.33      0.31       508\n",
      "\n",
      "        accuracy                           0.50      5100\n",
      "       macro avg       0.41      0.46      0.42      5100\n",
      "    weighted avg       0.57      0.50      0.52      5100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_valid)\n",
    "\n",
    "print(classification_report(y_pred, y_valid, target_names=encode_labels.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "worst-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'Models/attrib_classifier_gbcv.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-costs",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(X_df, y_df):\n",
    "    # Update X_df with number variables\n",
    "    numerical_features(X_df)\n",
    "    \n",
    "    # Tokenize the spacy goods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-plate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-customer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-observation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-survivor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "designing-banner",
   "metadata": {},
   "source": [
    "# AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "white-assessment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to H2O server at http://10.0.0.157:54323 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>08 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Los_Angeles</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.32.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 18 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>sparkling-water-okeefe_local-1618891679901</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>796 Mb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://10.0.0.157:54323</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>null</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>XGBoost, Algos, Amazon S3, Sparkling Water REST API Extensions, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.1 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -------------------------------------------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         08 secs\n",
       "H2O_cluster_timezone:       America/Los_Angeles\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.32.0.4\n",
       "H2O_cluster_version_age:    2 months and 18 days\n",
       "H2O_cluster_name:           sparkling-water-okeefe_local-1618891679901\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    796 Mb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  16\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://10.0.0.157:54323\n",
       "H2O_connection_proxy:       null\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         XGBoost, Algos, Amazon S3, Sparkling Water REST API Extensions, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.8.1 final\n",
       "--------------------------  -------------------------------------------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sparkling Water Context:\n",
      " * Sparkling Water Version: 3.32.0.4-1-3.0\n",
      " * H2O name: sparkling-water-okeefe_local-1618891679901\n",
      " * cluster size: 1\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (0,10.0.0.157,54321)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://10.0.0.157:54323 (CMD + click in Mac OSX)\n",
      "\n",
      "    \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-3e8b74dbc0bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pysparkling import *\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "ss = SparkSession.builder.getOrCreate()\n",
    "hc = H2OContext.getOrCreate()\n",
    "\n",
    "train = X_train\n",
    "train['label'] = y_train\n",
    "valid = X_valid\n",
    "valid['label'] = y_valid\n",
    "\n",
    "df_train = ss.createDataFrame(train)\n",
    "df_train_h2o = hc.asH2OFrame(df_train, \"train\")\n",
    "adult_train_h2o[\"label\"] = adult_train_h2o[\"label\"].asfactor()\n",
    "\n",
    "df_valid = ss.createDataFrame(valid)\n",
    "df_valid_h2o = hc.asH2OFrame(df_valid, \"valid\")\n",
    "df_valid_h2o[\"label\"] = df_valid_h2o[\"label\"].asfactor()\n",
    "\n",
    "predictors = df_valid_h2o.names[:]\n",
    "response = 'label'\n",
    "predictors.remove(response)\n",
    "\n",
    "model_automl = H2OAutoML(max_models=3, nfolds=5)\n",
    "model_automl.train(x=predictors,\n",
    "                   y=response,\n",
    "                   training_frame=df_train_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automl.leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.get_model(\"StackedEnsemble_AllModels_AutoML_20210307_183027\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automl.explain(df_train_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model #1:\n",
    "# Results for dataset without upsampling the minority values.\n",
    "#     \"none\" attribute was downsampled using the median of the known class counts\n",
    "\n",
    "#                      precision    recall  f1-score   support\n",
    "\n",
    "#  building_height       0.78      0.88      0.83       591\n",
    "#          max_dua       0.68      0.81      0.74      1373\n",
    "#          max_far       0.07      0.17      0.10        24\n",
    "# minimum_lot_sqft       0.92      0.68      0.78      1610\n",
    "#             none       0.68      0.64      0.66       619\n",
    "#    units_per_lot       0.05      0.09      0.07       133\n",
    "\n",
    "#         accuracy                           0.72      4350\n",
    "#        macro avg       0.53      0.55      0.53      4350\n",
    "#     weighted avg       0.76      0.72      0.73      4350\n",
    "\n",
    "\n",
    "\n",
    "# Model #2:\n",
    "# Upsampled minority values to the median of the dataset\n",
    "#    \"none\" attribute downsampled using the median of the known class counts\n",
    "\n",
    "#                   precision    recall  f1-score   support\n",
    "\n",
    "#  building_height       0.71      0.86      0.78       555\n",
    "#          max_dua       0.96      0.41      0.57      3865\n",
    "#          max_far       0.33      0.72      0.45       421\n",
    "# minimum_lot_sqft       0.54      0.86      0.66       740\n",
    "#             none       0.42      0.84      0.56       288\n",
    "#    units_per_lot       0.04      0.67      0.07        54\n",
    "\n",
    "#         accuracy                           0.55      5923\n",
    "#        macro avg       0.50      0.73      0.52      5923\n",
    "#     weighted avg       0.80      0.55      0.59      5923\n",
    "\n",
    "\n",
    "\n",
    "# Model #3:\n",
    "# Upsampling minority values\n",
    "#     \"none\" attribute downsampled using the sum of the the known class counts\n",
    "\n",
    "#                   precision    recall  f1-score   support\n",
    "\n",
    "#  building_height       0.78      0.62      0.69       840\n",
    "#          max_dua       0.22      0.53      0.31       679\n",
    "#          max_far       0.47      0.69      0.56       958\n",
    "# minimum_lot_sqft       0.66      0.59      0.62      1315\n",
    "#             none       0.94      0.60      0.73      5951\n",
    "#    units_per_lot       0.17      0.71      0.27       334\n",
    "\n",
    "#         accuracy                           0.61     10077\n",
    "#        macro avg       0.54      0.62      0.53     10077\n",
    "#     weighted avg       0.77      0.61      0.65     10077\n",
    "\n",
    "\n",
    "\n",
    "# Model #4:\n",
    "# Upsampled minority values to be: max_far: *10, units_per_lot: *2\n",
    "#    \"none\" attribute downsampled using the median of the known class counts\n",
    "\n",
    "#                   precision    recall  f1-score   support\n",
    "\n",
    "#  building_height       0.81      0.80      0.81       679\n",
    "#          max_dua       0.83      0.64      0.72      2132\n",
    "#          max_far       0.59      0.54      0.57       640\n",
    "# minimum_lot_sqft       0.77      0.75      0.76      1225\n",
    "#             none       0.56      0.78      0.65       418\n",
    "#    units_per_lot       0.01      0.67      0.02         6\n",
    "\n",
    "#         accuracy                           0.68      5100\n",
    "#        macro avg       0.59      0.69      0.59      5100\n",
    "#     weighted avg       0.76      0.68      0.71      5100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-boating",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "- Since we are looking for high levels of recall, model #1 seems to be the way to go! \n",
    "- Model #1 also had the best f1 score, though both models #2/#3 have a higher precision.\n",
    "- While max_far benefitted from upsampling (ESPECIALLY in recall!), units_per_lot didn't quite budge throughout\n",
    "    - Further research shows that upsampling max_far via the median value only increased by a factor of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-handling",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'attrib_classifier_model1.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "alien-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-lambda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learnpytorch",
   "language": "python",
   "name": "learnpytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
